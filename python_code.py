# -*- coding: utf-8 -*-
"""Python_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrbuSx3V0njHg4fqBureqbytCeVq_-Xu

# High-Dimensional Data Analysis: Dummy, Feature Engineering, LightGBM
> *ZHOU Shucheng*  

> *Based on Statistical ML Course Final Exam*

## Import Package & Data
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn.decomposition import PCA
import lightgbm as lgb
from sklearn.metrics import accuracy_score
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")

import os
from google.colab import drive
drive.mount('/content/gdrive')
os.chdir("/content/gdrive/MyDrive/Colab Notebooks/SDSC6001/Final")

D = open('Train.txt')
Data = D.readlines()
Columns = [eval(i) for i in Data[0].rstrip().split(' ')]
X = Data[1::]
X_New = [[] for i in range(len(Columns))]
for i in X:
    Temp = i.split(' ')[1::]
    for j in range(len(Temp)):
        X_New[j].append(eval(Temp[j]))
Dict = {}
for i in range(len(Columns)):
    Dict.update({Columns[i]:X_New[i]})
train = pd.DataFrame(Dict)

D = open('Test.txt')
Data = D.readlines()
Columns = [eval(i) for i in Data[0].rstrip().split(' ')]
X = Data[1::]
X_New = [[] for i in range(len(Columns))]
for i in X:
    Temp = i.split(' ')[1::]
    for j in range(len(Temp)):
        X_New[j].append(eval(Temp[j]))
Dict = {}
for i in range(len(Columns)):
    Dict.update({Columns[i]:X_New[i]})
test = pd.DataFrame(Dict)

"""## Dummy Variable"""

# dummy race
train = pd.get_dummies(train, columns=['race'])
test = pd.get_dummies(test, columns=['race'])
# split X, y
X, y = train.drop("PregnancyStatus", axis=1), train.loc[:,["PregnancyStatus"]]

"""## Feature Selection"""

# feature selection
selected_feature = SelectKBest(score_func=f_classif)
fit = selected_feature.fit(X, y)
scores = pd.DataFrame(fit.scores_)
columns = pd.DataFrame(X.columns)
feature_scores = pd.concat([columns, scores], axis=1)
feature_scores.columns = ['V','Score']
print(feature_scores.nlargest(20,'Score'))

index = feature_scores.nlargest(20,'Score').index
selected_feature_name = list(X[X.columns[index]].columns)
print(selected_feature_name)

"""## Data Normalization

### Split Numrical/Categorical Features
"""

numerical = [1] + list(range(4, 14)) + list(range(21, 24)) + list(range(29, 31)) + list(range(35, 46)) + [48] + list(range(52, 54))
numerical_name = list(train[train.columns[numerical]].columns)
print('numerical features:', numerical_name)
categorical = []
for i in range(1, 59):
    if i not in numerical:
        categorical.append(i)
categorical_name = list(train[train.columns[categorical]].columns)
multi_categorical_name = ['V33', 'V34', 'V35']
print('\nmulti_categorical features:', multi_categorical_name)
bi_categorical_name = [i for i in categorical_name if i not in multi_categorical_name]
print('\nbi_categorical features:',bi_categorical_name)

"""### Normalize X_train and X_valid"""

for i in range(0,3):
  l = list(train[['V33','V34','V35']].iloc[:,i])
  l1 = pd.Series(l)
  print(l1.value_counts())

df = train[numerical_name]
df_norm = (df - df.mean()) / df.std()
df_bi = train[bi_categorical_name]
## multi_categorical features are all not selected feature, so do not dummy
X_scaled = pd.concat((df_norm, df_bi), axis=1)
X_scaled_selected = X_scaled[selected_feature_name]

df_test = test[numerical_name]
df_norm_test = (df_test - df.mean()) / df.std()
df_bi_test = test[bi_categorical_name]

X_test_scaled = pd.concat((df_norm_test, df_bi_test), axis=1)
X_test_scaled_selected = X_test_scaled[selected_feature_name]

# split train and validation set
X_train, X_valid, y_train, y_valid = train_test_split(X_scaled_selected, y, train_size = 0.8, random_state = 21)

"""## LightGBM

### Fit Model
"""

clf = lgb.LGBMClassifier(random_state=21)
clf.fit(X_train, y_train)
y_valid_pred=clf.predict(X_valid)
accuracy_score(y_valid_pred, y_valid)

"""### GridSearch"""

# cv parameter for normal LGBM
from sklearn.model_selection import GridSearchCV
params = {'boosting_type': ['gbdt','dart'],
          'learning_rate':[0.001*i for i in range(20)],
          'num_leaves': [5*i for i in range(5)], 
          'n_estimators':[3*i for i in range(0,5,1)]}


clf = lgb.LGBMClassifier(class_weight='balanced', objective='binary')
results = GridSearchCV(clf, params, cv=10, scoring='accuracy')
results.fit(X, y)
print('best params:', results.best_params_)
print('best cv score:', results.best_score_)

"""## Some other try"""

# cv for normal LGBM
accuracys = []
for i in range(100):
  X_train, X_valid, y_train, y_valid = train_test_split(X_scaled_selected, y, train_size = 0.8, random_state = 21)
  clf = lgb.LGBMClassifier()
  clf.fit(X_train, y_train)
  y_valid_pred=clf.predict(X_valid)
  accuracy = accuracy_score(y_valid_pred, y_valid)
  accuracys.append(accuracy)
np.mean(accuracys)

# select pca column
V_col = X_train.filter(like='V').columns.values

col_pca = []
for i in range(len(X_train.columns)):
  col_i = X_train.columns.values[i]
  if col_i in V_col:
    l = len(X_train.iloc[:,i].unique())
    if l > 2:
      col_pca.append(col_i)

# cv for PCA + LGBM
accuracys = []
for i in range(200):
  X_train, X_valid, y_train, y_valid = train_test_split(X_scaled_selected, y, train_size = 0.8, random_state = i)
  
  # scale PCA part of train
  X_train_pca = pd.DataFrame(scale(X_train[col_pca]))
  X_train_pca.index = X_train.index
  X_train_pca.columns = col_pca
  # scale PCA part of valid
  X_valid_pca = pd.DataFrame(scale(X_valid[col_pca]))
  X_valid_pca.index = X_valid.index
  X_valid_pca.columns = col_pca
  # pca
  pca = PCA(n_components=10)
  X_train_pca_new = pca.fit_transform(X_train_pca)
  X_valid_pca_new = pca.transform(X_valid_pca)
  sum(pca.explained_variance_ratio_)

  # concat pca part and the rest
  X_train_rest = X_train.drop(col_pca, axis=1)
  X_train_new = pd.concat([X_train_rest, X_train_pca], axis=1)

  X_valid_rest = X_valid.drop(col_pca, axis=1)
  X_valid_new = pd.concat([X_valid_rest, X_valid_pca], axis=1)

  clf = lgb.LGBMClassifier()
  clf.fit(X_train_new, y_train)
  y_valid_pred=clf.predict(X_valid_new)
  accuracy = accuracy_score(y_valid_pred, y_valid)
  accuracys.append(accuracy)
np.mean(accuracys)



"""## Result of Test"""

y_test_pred=clf.predict(X_test_scaled_selected)
df_save = pd.DataFrame({'id':range(1, len(y_test_pred)+1),'class':y_test_pred})
df_save.to_csv('result.csv',index=None)